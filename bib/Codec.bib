
@article{a.fuldsethfuldsethTiles,
  title = {Tiles},
  author = {A. Fuldseth|Fuldseth, A},
  journaltitle = {Proc. JCT-VC F335, 6th Meeting of Joint Collaborative Team on Video Coding (JCT-VC) of ITU-T SG16 WP3 and ISO/IEC JTC1/SC29/WG11}
}

@inproceedings{akyaziComparisonCompressionEfficiency2018,
  title = {Comparison of {{Compression Efficiency}} between {{HEVC}}/{{H}}.265, {{VP9}} and {{AV1}} Based on {{Subjective Quality Assessments}}},
  booktitle = {2018 {{Tenth International Conference}} on {{Quality}} of {{Multimedia Experience}} ({{QoMEX}})},
  author = {Akyazi, Pinar and Ebrahimi, Touradj},
  date = {2018-05},
  pages = {1--6},
  publisher = {{IEEE}},
  location = {{Cagliari}},
  eventtitle = {2018 {{Tenth International Conference}} on {{Quality}} of {{Multimedia Experience}} ({{QoMEX}})},
  isbn = {978-1-5386-2605-4}
}

@inproceedings{akyaziComparisonCompressionEfficiency2018a,
  title = {Comparison of {{Compression Efficiency}} between {{HEVC}}/{{H}}.265, {{VP9}} and {{AV1}} Based on {{Subjective Quality Assessments}}},
  booktitle = {2018 {{Tenth International Conference}} on {{Quality}} of {{Multimedia Experience}} ({{QoMEX}})},
  author = {Akyazi, Pinar and Ebrahimi, Touradj},
  date = {2018-05},
  pages = {1--6},
  publisher = {{IEEE}},
  location = {{Cagliari}},
  eventtitle = {2018 {{Tenth International Conference}} on {{Quality}} of {{Multimedia Experience}} ({{QoMEX}})},
  isbn = {978-1-5386-2605-4}
}

@standard{audio-videotransportworkinggroupRTPTransportProtocol1996,
  title = {{{RTP}}: {{A Transport Protocol}} for {{Real}}-{{Time Applications}}},
  shorttitle = {{{RTP}}},
  author = {{Audio-Video Transport Working Group} and Schulzrinne, H. and Casner, S. and Frederick, R. and Jacobson, V.},
  date = {1996-01},
  publisher = {{RFC Editor}},
  langid = {english},
  number = {RFC1889}
}

@inproceedings{baiSaliencyBasedRate2016,
  title = {Saliency Based Rate Control Scheme for High Efficiency Video Coding},
  booktitle = {2016 {{Asia}}-{{Pacific Signal}} and {{Information Processing Association Annual Summit}} and {{Conference}} ({{APSIPA}})},
  author = {Bai, Lixun and Song, Li and Xie, Rong and Xie, Jianfeng and Chen, M.},
  date = {2016-12},
  pages = {1--6},
  publisher = {{IEEE}},
  location = {{Jeju, South Korea}},
  eventtitle = {2016 {{Asia}}-{{Pacific Signal}} and {{Information Processing Association Annual Summit}} and {{Conference}} ({{APSIPA}})},
  isbn = {978-988-14768-2-1}
}

@inproceedings{barmanEvaluationVideoQuality2018a,
  title = {An {{Evaluation}} of {{Video Quality Assessment Metrics}} for {{Passive Gaming Video Streaming}}},
  booktitle = {Proceedings of the 23rd {{Packet Video Workshop}} on {{ZZZ}} - {{PV}} '18},
  author = {Barman, Nabajeet and Schmidt, Steven and Zadtootaghaj, Saman and Martini, Maria G. and Möller, Sebastian},
  date = {2018},
  pages = {7--12},
  publisher = {{ACM Press}},
  location = {{Amsterdam, Netherlands}},
  abstract = {Video quality assessment is imperative to estimate and hence manage the ality of Experience (QoE) in video streaming applications to the end-user. Recent years have seen a tremendous advancement in the eld of objective video quality assessment (VQA) metrics, with the development of models that can predict the quality of the videos streamed over the Internet. However, no work so far has a empted to study the performance of such quality assessment metrics on gaming videos, which are arti cial and synthetic and have di erent streaming requirements than traditionally streamed videos. Towards this end, we present in this paper a study of the performance of objective quality assessment metrics for gaming videos considering passive streaming applications. Objective quality assessment considering eight widely used VQA metrics is performed on a dataset of 24 reference videos and 576 compressed sequences obtained by encoding them at 24 di erent resolution-bitrate pairs. We present an evaluation of the performance behavior of the VQA metrics. Our results indicate that VMAF predicts subjective video quality ratings the best, while NIQE turns out to be a promising alternative as a no-reference metric in some scenarios.},
  eventtitle = {The 23rd {{Packet Video Workshop}}},
  isbn = {978-1-4503-5773-9},
  langid = {english}
}

@article{bjontegaardCalculationAveragePSNR2001,
  title = {Calculation of Average {{PSNR}} Differences between {{RD}}-Curves},
  author = {Bjontegaard, G.},
  date = {2001},
  journaltitle = {VCEG-M33}
}

@article{borjiStateoftheArtVisualAttention2013,
  title = {State-of-the-{{Art}} in {{Visual Attention Modeling}}},
  author = {Borji, Ali and Itti, Laurent},
  date = {2013-01},
  journaltitle = {IEEE Trans. Pattern Anal. Mach. Intell.},
  volume = {35},
  pages = {185--207},
  issn = {0162-8828, 2160-9292},
  number = {1}
}

@inproceedings{chenOverviewCoreCoding2018,
  title = {An {{Overview}} of {{Core Coding Tools}} in the {{AV1 Video Codec}}},
  booktitle = {2018 {{Picture Coding Symposium}} ({{PCS}})},
  author = {Chen, Yue and Murherjee, Debargha and Han, Jingning and Grange, Adrian and Xu, Yaowu and Liu, Zoe and Parker, Sarah and Chen, Cheng and Su, Hui and Joshi, Urvang and Chiang, Ching-Han and Wang, Yunqing and Wilkins, Paul and Bankoski, Jim and Trudeau, Luc and Egge, Nathan and Valin, Jean-Marc and Davies, Thomas and Midtskogen, Steinar and Norkin, Andrey and de Rivaz, Peter},
  date = {2018-06},
  pages = {41--45},
  publisher = {{IEEE}},
  location = {{San Francisco, CA}},
  abstract = {AV1 is an emerging open-source and royalty-free video compression format, which is jointly developed and finalized in early 2018 by the Alliance for Open Media (AOMedia) industry consortium. The main goal of AV1 development is to achieve substantial compression gain over state-of-the-art codecs while maintaining practical decoding complexity and hardware feasibility. This paper provides a brief technical overview of key coding techniques in AV1 along with preliminary compression performance comparison against VP9 and HEVC.},
  eventtitle = {2018 {{Picture Coding Symposium}} ({{PCS}})},
  isbn = {978-1-5386-4160-6},
  langid = {english},
  options = {useprefix=true}
}

@inproceedings{chiangMultiPassCodingMode2019,
  title = {A {{Multi}}-{{Pass Coding Mode Search Framework For AV1 Encoder Optimization}}},
  booktitle = {2019 {{Data Compression Conference}} ({{DCC}})},
  author = {Chiang, Ching-Han and Han, Jingning and Xu, Yaowu},
  date = {2019-03},
  pages = {458--467},
  publisher = {{IEEE}},
  location = {{Snowbird, UT, USA}},
  abstract = {The AV1 codec recently released by the Alliance of Open Media provides nearly 30\% BDrate reduction over its predecessor VP9. It substantially extends the available coding block sizes and supports a wide range of prediction modes. There are also a large variety of transform kernel types and sizes. The combination provides an extremely wide range of flexible coding options. To translate such flexibility into compression efficiency, the encoder needs to conduct an extensive search over the space of coding modes. Optimization of the encoder complexity and compression efficiency trade-off is critical to productionizing AV1. Many research efforts have been devoted to devising feature space based pruning methods ranging from decision rules based on some simple observations to more complex neural network models. A multi-pass coding mode search framework is proposed in this work to provide a structural approach to reduce the search volume. It decomposes the original high dimensional space search into cascaded stages of lower dimensional space searches. To retain a near optimal search result, the scheme departs from conventional dimension reduction approach in which one retains a single winner at each stage, and uses that winner for the next stage (dimension). Instead, this framework retains a subset of the states that are the most likely winners at each stage, which are then fed into the next stage to find the next subset of winners. The subset size at each stage is determined by the likelihood that the optimal route will be captured in the current stage. Changing this likelihood parameter tunes the encoder for speed and compression performance trade-off. This framework can integrate with most existing feature based methods at its various stages. The framework provides 60\% encoding time reduction at the expense of 0.6\% compression loss in libaom AV1 encoder.},
  eventtitle = {2019 {{Data Compression Conference}} ({{DCC}})},
  isbn = {978-1-72810-657-1},
  langid = {english}
}

@article{chun-hsienchouPerceptuallyTunedSubband1995,
  title = {A Perceptually Tuned Subband Image Coder Based on the Measure of Just-Noticeable-Distortion Profile},
  author = {{Chun-Hsien Chou} and {Yun-Chin Li}},
  date = {1995-12},
  journaltitle = {IEEE Trans. Circuits Syst. Video Technol.},
  volume = {5},
  pages = {467--476},
  issn = {10518215},
  number = {6}
}

@article{correaParetoBasedMethodHigh2016,
  title = {Pareto-{{Based Method}} for {{High Efficiency Video Coding With Limited Encoding Time}}},
  author = {Correa, Guilherme and Assuncao, Pedro A. and Agostini, Luciano Volcan and da Silva Cruz, Luis A.},
  date = {2016-09},
  journaltitle = {IEEE Trans. Circuits Syst. Video Technol.},
  volume = {26},
  pages = {1734--1745},
  issn = {1051-8215, 1558-2205},
  abstract = {Several different methods have been investigated in recent years, aiming at computational complexity reduction and scaling of High Efficiency Video Coding (HEVC) software implementations. However, maintaining the encoding time per frame or group of pictures (GOPs) below an adjustable upper bound is still an open research issue. A solution for this problem is devised in this paper based on a set of Pareto-efficient encoding configurations, identified through rate-distortion-complexity analysis. The proposed method combines a medium-granularity encoding time control with a fine-granularity encoding time control to accurately limit the HEVC encoding time below a predefined target for each GOP. It is shown that the encoding time can be kept below a desired target for a wide range of encoding time reductions, e.g., up to 90\% in comparison with the original encoder. The results also show that compression efficiency loss (Bjøntegaard delta-rate) varies from negligible (0.16\%) to moderate (9.83\%) in the extreme case of 90\% computational complexity reduction.},
  langid = {english},
  number = {9},
  options = {useprefix=true}
}

@article{correaPerformanceComputationalComplexity2012,
  title = {Performance and {{Computational Complexity Assessment}} of {{High}}-{{Efficiency Video Encoders}}},
  author = {Correa, Guilherme and Assuncao, Pedro and Agostini, Luciano and da Silva Cruz, Luis A.},
  date = {2012-12},
  journaltitle = {IEEE Trans. Circuits Syst. Video Technol.},
  volume = {22},
  pages = {1899--1909},
  issn = {1051-8215, 1558-2205},
  abstract = {This paper presents a performance evaluation study of coding efficiency versus computational complexity for the forthcoming High Efficiency Video Coding (HEVC) standard. A thorough experimental investigation was carried out to identify the tools that most affect the encoding efficiency and computational complexity of the HEVC encoder. A set of 16 different encoding configurations was created to investigate the impact of each tool, varying the encoding parameter set and comparing the results with a baseline encoder. This paper shows that, even though the computational complexity increases monotonically from the baseline to the most complex configuration, the encoding efficiency saturates at some point. Moreover, the results of this paper provide relevant information for implementation of complexity-constrained encoders by taking into account the tradeoff between complexity and coding efficiency. It is shown that low-complexity encoding configurations, defined by careful selection of coding tools, achieve coding efficiency comparable to that of high-complexity configurations.},
  langid = {english},
  number = {12},
  options = {useprefix=true}
}

@inproceedings{groisCodingEfficiencyComparison2016,
  title = {Coding Efficiency Comparison of {{AV1}}/{{VP9}}, {{H}}.265/{{MPEG}}-{{HEVC}}, and {{H}}.264/{{MPEG}}-{{AVC}} Encoders},
  booktitle = {2016 {{Picture Coding Symposium}} ({{PCS}})},
  author = {Grois, Dan and Nguyen, Tung and Marpe, Detlev},
  date = {2016},
  pages = {1--5},
  publisher = {{IEEE}},
  location = {{Nuremberg, Germany}},
  eventtitle = {2016 {{Picture Coding Symposium}} ({{PCS}})},
  isbn = {978-1-5090-5966-9}
}

@inproceedings{guoBayesianApproachBlock2018,
  title = {A {{Bayesian Approach}} to {{Block Structure Inference}} in {{AV1}}-{{Based Multi}}-{{Rate Video Encoding}}},
  booktitle = {2018 {{Data Compression Conference}}},
  author = {Guo, Bichuan and Chen, Xinyao and Gu, Jiawen and Han, Yuxing and Wen, Jiangtao},
  date = {2018-03},
  pages = {383--392},
  publisher = {{IEEE}},
  location = {{Snowbird, UT}},
  eventtitle = {2018 {{Data Compression Conference}} ({{DCC}})},
  isbn = {978-1-5386-4883-4}
}

@inproceedings{guoqingxiangImprovedAdaptiveQuantization2017,
  title = {An Improved Adaptive Quantization Method Based on Perceptual {{CU}} Early Splitting for {{HEVC}}},
  booktitle = {2017 {{IEEE International Conference}} on {{Consumer Electronics}} ({{ICCE}})},
  author = {{Guoqing Xiang} and {Huizhu Jia} and {Mingyuan Yang} and {Jie Liu} and {Chuang Zhu} and {Yuan Li} and {Xiaodong Xie}},
  date = {2017},
  pages = {362--365},
  publisher = {{IEEE}},
  location = {{Las Vegas, NV, USA}},
  eventtitle = {2017 {{IEEE International Conference}} on {{Consumer Electronics}} ({{ICCE}})},
  isbn = {978-1-5090-5544-9}
}

@article{huynh-thuAccuracyPSNRPredicting2012,
  title = {The Accuracy of {{PSNR}} in Predicting Video Quality for Different Video Scenes and Frame Rates},
  author = {Huynh-Thu, Quan and Ghanbari, Mohammed},
  date = {2012-01},
  journaltitle = {Telecommun Syst},
  volume = {49},
  pages = {35--48},
  issn = {1018-4864, 1572-9451},
  langid = {english},
  number = {1}
}

@standard{InformationTechnologyCoding,
  title = {Information Technology — {{Coding}} of Audio-Visual Objects — {{Part}} 12: {{ISO}} Base Media File Format},
  publisher = {{International Organization for Standardization}},
  number = {ISO/IEC 14496-12},
  type = {Standard}
}

@standard{InformationTechnologyGeneric,
  title = {Information Technology — {{Generic}} Coding of Moving Pictures and Associated Audio Information — {{Part}} 1: {{Systems}}},
  shorttitle = {{{ISO}}/{{IEC}} 13818-1:2019},
  publisher = {{International Organization for Standardization}},
  number = {ISO/IEC 13818-1},
  type = {Standard}
}

@article{kimFastInterPredictionBased2019,
  title = {Fast {{Inter}}-{{Prediction}} Based on {{Decision Trees}} for {{AV1}} Encoding},
  author = {Kim, Jieon and Blasi, Saverio and Dias, Andre Seixas and Mrak, Marta and Izquierdo, Ebroul},
  date = {2019-08-29},
  abstract = {The AOMedia Video 1 (AV1) standard can achieve considerable compression efficiency thanks to the usage of many advanced tools and improvements, such as advanced interprediction modes. However, these come at the cost of high computational complexity of encoder, which may limit the benefits of the standard in practical applications. This paper shows that not all sequences benefit from using all such modes, which indicates that a number of encoder optimisations can be introduced to speed up AV1 encoding. A method based on decision trees is proposed to selectively decide whether to test all inter modes. Appropriate features are extracted and used to perform the decision for each block. Experimental results show that the proposed method can reduce the encoding time on average by 43.4\% with limited impact on the coding efficiency.},
  archivePrefix = {arXiv},
  eprint = {1908.11166},
  eprinttype = {arxiv},
  keywords = {Electrical Engineering and Systems Science - Image and Video Processing},
  langid = {english},
  primaryClass = {eess}
}

@inproceedings{laudeComparisonJEMAV12018,
  title = {A {{Comparison}} of {{JEM}} and {{AV1}} with {{HEVC}}: {{Coding Tools}}, {{Coding Efficiency}} and {{Complexity}}},
  shorttitle = {A {{Comparison}} of {{JEM}} and {{AV1}} with {{HEVC}}},
  booktitle = {2018 {{Picture Coding Symposium}} ({{PCS}})},
  author = {Laude, Thorsten and Adhisantoso, Yeremia Gunawan and Voges, Jan and Munderloh, Marco and Ostermann, Jorn},
  date = {2018-06},
  pages = {36--40},
  publisher = {{IEEE}},
  location = {{San Francisco, CA}},
  eventtitle = {2018 {{Picture Coding Symposium}} ({{PCS}})},
  isbn = {978-1-5386-4160-6}
}

@article{laudeComprehensiveVideoCodec2019,
  title = {A {{Comprehensive Video Codec Comparison}}},
  author = {Laude, Thorsten and Adhisantoso, Yeremia Gunawan and Voges, Jan and Munderloh, Marco and Ostermann, Jörn},
  date = {2019},
  journaltitle = {APSIPA Transactions on Signal and Information Processing},
  volume = {8},
  pages = {e30},
  issn = {2048-7703},
  abstract = {In this paper, we compare the video codecs AV1 (version 1.0.0-2242 from August 2019), HEVC (HM and x265), AVC (x264), the exploration software JEM which is based on HEVC, and the VVC (successor of HEVC) test model VTM (version 4.0 from February 2019) under two fair and balanced configurations: All Intra for the assessment of intra coding and Maximum Coding Efficiency with all codecs being tuned for their best coding efficiency settings. VTM achieves the highest coding efficiency in both configurations, followed by JEM and AV1. The worst coding efficiency is achieved by x264 and x265, even in the placebo preset for highest coding efficiency. AV1 gained a lot in terms of coding efficiency compared to previous versions and now outperforms HM by 24\% BD-Rate gains. VTM gains 5\% over AV1 in terms of BD-Rates. By reporting separate numbers for JVET and AOM test sequences, it is ensured that no bias in the test sequences exists. When comparing only intra coding tools, it is observed that the complexity increases exponentially for linearly increasing coding efficiency.},
  langid = {english}
}

@inproceedings{leeComparisonObjectiveQuality2017,
  title = {Comparison of Objective Quality Models for Adaptive Bit-Streaming Services},
  booktitle = {2017 8th {{International Conference}} on {{Information}}, {{Intelligence}}, {{Systems}} \& {{Applications}} ({{IISA}})},
  author = {Lee, C. and Woo, S. and Baek, S. and Han, J. and Chae, J. and Rim, J.},
  date = {2017-08},
  pages = {1--4},
  publisher = {{IEEE}},
  location = {{Larnaca}},
  eventtitle = {2017 8th {{International Conference}} on {{Information}}, {{Intelligence}}, {{Systems}} \& {{Applications}} ({{IISA}})},
  isbn = {978-1-5386-3731-9}
}

@inproceedings{liIntraBlockCopy2018,
  title = {Intra {{Block Copy}} for {{Screen Content}} in the {{Emerging AV1 Video Codec}}},
  booktitle = {2018 {{Data Compression Conference}}},
  author = {Li, Jiahao and Su, Hui and Converse, Alex and Li, Bin and Zhou, Roger and Lin, Bruce and Xu, Jizheng and Lu, Yan and Xiong, Ruiqin},
  date = {2018-03},
  pages = {355--364},
  publisher = {{IEEE}},
  location = {{Snowbird, UT}},
  abstract = {Screen content coding plays an important role in many applications. To meet the growing demands of screen content coding, the emerging AV1 video codec incorporates several coding tools, which are specially designed for screen content utilizing its distinctive characteristics. Among these tools, the intra block copy utilizes the characteristic that repeating patterns frequently occur in screen content. This paper presents the technology of intra block copy in AV1. In particular, to efficiently search the predictor in the reconstructed regions of the current picture, AV1 uses the hash matching method at the encoder side. For the generation of hash table, a bottom-to-up manner is adopted to reduce the redundant computation and then decrease the encoding time. In addition, several constraints are involved to facilitate hardware design. Experimental results demonstrate that the intra block copy in AV1 can bring 27.1\% bitrate saving for screen content. When compared with the non hash-based intra block copy, the hash-based method achieves 12.2\% bitrate saving.},
  eventtitle = {2018 {{Data Compression Conference}} ({{DCC}})},
  isbn = {978-1-5386-4883-4},
  langid = {english}
}

@inproceedings{linEfficientAV1Video2018,
  title = {Efficient {{AV1 Video Coding Using}} a {{Multi}}-Layer {{Framework}}},
  booktitle = {2018 {{Data Compression Conference}}},
  author = {Lin, Wei-Ting and Liu, Zoe and Mukherjee, Debargha and Han, Jingning and Wilkins, Paul and Xu, Yaowu and Rose, Kenneth},
  date = {2018-03},
  pages = {365--373},
  publisher = {{IEEE}},
  location = {{Snowbird, UT}},
  abstract = {This paper proposes a multi-layer multi-reference prediction framework for effective video compression. Current AOM/AV1 baseline uses three reference frames for the inter prediction of each video frame. This paper first presents a new coding tool that extends the total number of reference frames in both forward and backward prediction directions. A multilayer framework is then described, which suggests the encoder design and places different reference frames within one Golden Frame (GF) group to different layers. The multi-layer framework leverages the existing coding tools in the AV1 baseline, including the tool of “show existing frame” and the reference frame buffer update module of a wide flexibility. The use of extended ALTREF FRAMEs is proposed, and multiple ALTREF FRAME candidates are selected and widely spaced within one GF group. ALTREF FRAME is a constructed, noshow reference obtained through temporal filtering of a look-ahead frame. In the multi-layer structure, one reference frame may serve different roles for the encoding of different frames through the virtual index manipulation. The experimental results have been collected over several video test sets of various resolutions and characteristics both texture- and motionwise, which demonstrate that the proposed approach achieves a consistent coding gain compared to the AV1 baseline. For instance, using PSNR as the distortion metric, an average bitrate saving of 5.57+\% in BDRate is obtained for the CIF-level resolution set, some of which has a gain of up to 13+\%, and 4.47\% on average for the VGA-level resolution set, some of which up to 18+\%.},
  eventtitle = {2018 {{Data Compression Conference}} ({{DCC}})},
  isbn = {978-1-5386-4883-4},
  langid = {english}
}

@inproceedings{midtskogenAv1ConstrainedDirectional2018,
  title = {The {{Av1 Constrained Directional Enhancement Filter}} ({{Cdef}})},
  booktitle = {2018 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}} ({{ICASSP}})},
  author = {Midtskogen, Steinar and Valin, Jean-Marc},
  date = {2018-04},
  pages = {1193--1197},
  publisher = {{IEEE}},
  location = {{Calgary, AB}},
  eventtitle = {{{ICASSP}} 2018 - 2018 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}} ({{ICASSP}})},
  isbn = {978-1-5386-4658-8}
}

@article{misraOverviewTilesHEVC2013,
  title = {An {{Overview}} of {{Tiles}} in {{HEVC}}},
  author = {Misra, Kiran and Segall, Andrew and Horowitz, Michael and Xu, Shilin and Fuldseth, Arild and Zhou, Minhua},
  date = {2013-12},
  journaltitle = {IEEE J. Sel. Top. Signal Process.},
  volume = {7},
  pages = {969--977},
  issn = {1932-4553, 1941-0484},
  number = {6}
}

@inproceedings{norkinFilmGrainSynthesis2018,
  title = {Film {{Grain Synthesis}} for {{AV1 Video Codec}}},
  booktitle = {2018 {{Data Compression Conference}}},
  author = {Norkin, Andrey and Birkbeck, Neil},
  date = {2018-03},
  pages = {3--12},
  publisher = {{IEEE}},
  location = {{Snowbird, UT}},
  abstract = {Film grain is abundant in TV and movie content. It is often part of the creative intent and needs to be preserved while encoding. However, the random nature of film grain is difficult to compress using traditional coding tools. This paper describes a film grain modeling and synthesis algorithm proposed for the AV1 video codec. At the encoder, an autoregressive model of film grain is transmitted relative to a denoised signal, and the film grain strength is modeled as a function of intensity. The corresponding renoising at the decoder is implemented using an efficient block-based approach suitable for use in consumer electronic devices. Preliminary results indicate that the approach can give significant bitrate savings (up to 50\%) on sequences with heavy film grain.},
  eventtitle = {2018 {{Data Compression Conference}} ({{DCC}})},
  isbn = {978-1-5386-4883-4},
  langid = {english}
}

@standard{pantosHTTPLiveStreaming2017,
  title = {{{HTTP Live Streaming}}},
  author = {Pantos, R. and May, W.},
  date = {2017-08},
  publisher = {{RFC Editor}},
  langid = {english},
  number = {RFC8216}
}

@standard{schulzrinneRealTimeStreaming1998,
  title = {Real {{Time Streaming Protocol}} ({{RTSP}})},
  author = {Schulzrinne, H. and Rao, A. and Lanphier, R.},
  date = {1998-04},
  publisher = {{RFC Editor}},
  langid = {english},
  number = {RFC2326}
}

@standard{schulzrinneRealTimeStreamingProtocol2016,
  title = {Real-{{Time Streaming Protocol Version}} 2.0},
  author = {Schulzrinne, H. and Rao, A. and Lanphier, R. and Westerlund, M. and Stiemerling, M.},
  date = {2016-12},
  publisher = {{RFC Editor}},
  langid = {english},
  number = {RFC7826}
}

@standard{schulzrinneRTPTransportProtocol2003,
  title = {{{RTP}}: {{A Transport Protocol}} for {{Real}}-{{Time Applications}}},
  shorttitle = {{{RTP}}},
  author = {Schulzrinne, H. and Casner, S. and Frederick, R. and Jacobson, V.},
  date = {2003-07},
  publisher = {{RFC Editor}},
  langid = {english},
  number = {RFC3550}
}

@article{sullivanRatedistortionOptimizationVideo1998,
  title = {Rate-Distortion Optimization for Video Compression},
  author = {Sullivan, G.J. and Wiegand, T.},
  date = {1998-11},
  journaltitle = {IEEE Signal Process. Mag.},
  volume = {15},
  pages = {74--90},
  issn = {10535888},
  number = {6}
}

@article{trowAV1ImplementationPerformance2020,
  title = {{{AV1}}: {{Implementation}}, {{Performance}}, and {{Applications}}},
  author = {Trow, Ian},
  date = {2020},
  journaltitle = {SMPTE Motion Imaging Journal},
  volume = {129},
  pages = {51--56},
  abstract = {With the finalization of the AVI specification, the Alliance for Open Media (AOM) has set high expectations for it. The prospect of a royalty-free alternative to high efficiency video coding (HEVC) has many supporters in the industry, particularly those seeking a standard for streaming applications that is optimized for over-the-top (OTT) delivery quite excited. Fundamental to AV1’s success will be the transfer of a toolset of efficient software implementations that can deliver the expected performance over existing compression standards within the constraints of future server provision. Efficient implementations of AV1 will require a careful balance between utilizing bespoke processor features to offload demanding processor-intensive functions and the desire to have a platform-agnostic compression standard that can be applied across a wide range of infrastructures. As with all complex compression schemes, realizing a software mapping of the toolset is crucial. This is true for AV1, which, being royalty-free, utilizes algorithms and methods that are different from those used in the Motion Picture Experts Group (MPEG) suite of standards. This article will look at the application challenges facing AV1 and compare its objective performance to that of the HEVC in terms of bitrate efficiency and encode time.},
  langid = {english}
}

@inproceedings{trudeauPredictingChromaLuma2018a,
  title = {Predicting {{Chroma}} from {{Luma}} in {{AV1}}},
  booktitle = {2018 {{Data Compression Conference}}},
  author = {Trudeau, Luc and Egge, Nathan and Barr, David},
  date = {2018-03},
  pages = {374--382},
  publisher = {{IEEE}},
  location = {{Snowbird, UT}},
  eventtitle = {2018 {{Data Compression Conference}} ({{DCC}})},
  isbn = {978-1-5386-4883-4}
}

@article{wuJustNoticeableDifference2013,
  title = {Just {{Noticeable Difference Estimation}} for {{Images With Free}}-{{Energy Principle}}},
  author = {Wu, Jinjian and Shi, Guangming and Lin, Weisi and Liu, Anmin and Qi, Fei},
  date = {2013-11},
  journaltitle = {IEEE Trans. Multimedia},
  volume = {15},
  pages = {1705--1710},
  issn = {1520-9210, 1941-0077},
  abstract = {In this paper, we introduce a novel just noticeable difference (JND) estimation model based on the unified brain theory, namely the freeenergy principle. The existing pixel-based JND models mainly consider the orderly factors and always underestimate the JND threshold of the disorderly region. Recent research indicates that the human visual system (HVS) actively predicts the orderly information and avoids the residual disorderly uncertainty for image perception and understanding. Thus, we suggest that there exists disorderly concealment effect which results in high JND threshold of the disorderly region. Beginning with the Bayesian inference, we deduce an autoregressive model to imitate the active prediction of the HVS. Then, we estimate the disorderly concealment effect for the novel JND model. Experimental results confirm that the proposed JND model outperforms the relevant existing ones. Furthermore, we apply the proposed JND model in image compression, and around 15\% of bit rate can be reduced without jeopardizing the perceptual quality.},
  langid = {english},
  number = {7}
}

@article{wuPatternMaskingEstimation2013,
  title = {Pattern {{Masking Estimation}} in {{Image With Structural Uncertainty}}},
  author = {Wu, Jinjian and Lin, Weisi and Shi, Guangming and Wang, Xiaotian and Li, Fu},
  date = {2013-12},
  journaltitle = {IEEE Trans. on Image Process.},
  volume = {22},
  pages = {4892--4904},
  issn = {1057-7149, 1941-0042},
  number = {12}
}

@article{yangJustNoticeableDistortion2005,
  title = {Just Noticeable Distortion Model and Its Applications in Video Coding},
  author = {Yang, X.K. and Ling, W.S. and Lu, Z.K. and Ong, E.P. and Yao, S.S.},
  date = {2005-08},
  journaltitle = {Signal Processing: Image Communication},
  volume = {20},
  pages = {662--680},
  issn = {09235965},
  langid = {english},
  number = {7}
}

@inproceedings{zhangJustNoticeableDistortionEstimation2005,
  title = {Just-{{Noticeable Distortion Estimation}} for {{Image Pixels}}},
  booktitle = {2005 {{IEEE}} 7th {{Workshop}} on {{Multimedia Signal Processing}}},
  author = {Zhang, X.h. and Lin, W.s. and Xue, P.},
  date = {2005-10},
  pages = {1--4},
  publisher = {{IEEE}},
  location = {{Shanghai}},
  eventtitle = {2005 {{IEEE}} 7th {{Workshop}} on {{Multimedia Signal Processing}}},
  isbn = {978-0-7803-9288-5 978-0-7803-9289-2}
}

@inproceedings{zhaoWavefrontParallelProcessing2018,
  title = {Wavefront {{Parallel Processing}} for {{AV1 Encoder}}},
  booktitle = {2018 {{Picture Coding Symposium}} ({{PCS}})},
  author = {Zhao, Yikai and Wen, Jiangtao},
  date = {2018-06},
  pages = {101--105},
  publisher = {{IEEE}},
  location = {{San Francisco, CA}},
  abstract = {The emerging AV1 coding standard brings even higher computational complexity than current coding standards, but does not support traditional Wavefront Parallel Processing (WPP) approach due to the lacking of syntax support. In this paper we introduced a novel framework to implement WPP for AV1 encoder that is compatible with current decoder without additional bitstream syntax support, where mode selection is processed in wavefront parallel before entropy encoding and entropy contexts for rate-distortion optimization are predicted. Based on this framework, context prediction algorithms that use same data dependency model as previous works in H.264 and HEVC are implemented. Furthermore, we proposed an optimal context prediction algorithm specifically for AV1. Experimental results showed that our framework with proposed optimal algorithm yields good parallelism and scalability (over 10x speed-up with 16 threads for 4k sequences) with little coding performance loss (less than 0.2\% bitrate increasing).},
  eventtitle = {2018 {{Picture Coding Symposium}} ({{PCS}})},
  isbn = {978-1-5386-4160-6},
  langid = {english}
}

@inproceedings{zhuJNDbasedPerceptualRate2019,
  title = {{{JND}}-Based {{Perceptual Rate Distortion Optimization}} for {{AV1 Encoder}}},
  booktitle = {2019 {{Picture Coding Symposium}} ({{PCS}})},
  author = {Zhu, Chen and Song, Li and Xie, Rong and Han, Jingning and Xu, Yaowu},
  date = {2019-11},
  pages = {1--5},
  publisher = {{IEEE}},
  location = {{Ningbo, China}},
  abstract = {AV1 is the next-generation open video coding format, and it can achieve significant coding efficiency with novel coding tools. It supports Lagrangian rate distortion optimization (RDO) method to optimize the coding performance. However, the distortion and the Lagrangian multiplier used in RDO ignore the characteristics of human visual system (HVS), which leads to insufficiency for perceptual video coding. To solve this problem, a perceptual RDO scheme based on the Just Noticeable Distortion (JND) threshold of HVS is proposed. The JND for each pixel is first measured according to three perceptual features: luminance adaptation, masking effects and structure sensitivity. Based on the observation that the regions with smaller distortion visibility thresholds are more sensitive to HVS, a JND-based Lagrangian multiplier is derived to adaptively adjust the rate-distortion (RD) performance for each coding block. Experiments demonstrate that the proposed method can achieve an average SSIM-based -3.93\% BD-Rate saving compared with the original AV1 encoder, which effectively improve the coding performance.},
  eventtitle = {2019 {{Picture Coding Symposium}} ({{PCS}})},
  isbn = {978-1-72814-704-8},
  langid = {english}
}


